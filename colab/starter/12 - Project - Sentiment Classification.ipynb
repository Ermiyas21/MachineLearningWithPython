{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7adfeb",
   "metadata": {},
   "source": [
    "<a \n",
    " href=\"https://colab.research.google.com/github/LearnPythonWithRune/MachineLearningWithPython/blob/main/colab/starter/12 - Project - Sentiment Classification.ipynb\"\n",
    " target=\"_parent\">\n",
    "<img \n",
    " src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fa4f2",
   "metadata": {},
   "source": [
    "# Project: Sentiment Classification\n",
    "- Make a model to determine whether a tweet positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd592d25",
   "metadata": {},
   "source": [
    "### Step 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d3526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c6e9000",
   "metadata": {},
   "source": [
    "### Step 2: Download the sample tweets\n",
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b640542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feccae3b",
   "metadata": {},
   "source": [
    "### Step 3: The tweets\n",
    "- Get the positive and negative tweets.\n",
    "    - HINT: You access the positive tweets by: **nltk.corpus.twitter_samples.strings('positive_tweets.json')**\n",
    "    - HINT: Similarly for the negative tweets.\n",
    "- Notice: There is also tweets with no sentiment - we will ignore them in this project\n",
    "- Check a few tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f64c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a254405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac2b506",
   "metadata": {},
   "source": [
    "### Step 4: Tokenize the tweets\n",
    "- You get the tokenized tweets as follows:\n",
    "    - **nltk.corpus.twitter_samples.tokenized('positive_tweets.json')**\n",
    "    - Simlarly for **negative_tweets**\n",
    "- Why tokenize?\n",
    "    - To make processing easier\n",
    "- Check a few tweets (tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02322421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01873d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce77587",
   "metadata": {},
   "source": [
    "### Step 5: Remove noise from data\n",
    "- The following tokens do not add value in our analysis\n",
    "    - Twitter usernames (starting with @)\n",
    "    - Hyperlinks (starting with http:// or https://)\n",
    "    - Punctuation and special characters\n",
    "        - HINT: if word in **string.punctuation**\n",
    "    - Numeric values only\n",
    "        - HINT: use **.isnumeric()**\n",
    "    - If word is a stopword ([wiki](https://en.wikipedia.org/wiki/Stop_word))\n",
    "        - HINT: Check if lower case word is in **stopwords.words('english')**\n",
    "- To simplify createa a helper function **is_clean** to check for the above\n",
    "- Create another helper function **clean_tokens**\n",
    "    - The function takes **tokens** (a list of tokens) as input\n",
    "    - Then returns a list of tokens, where **is_clean** has been used to filter\n",
    "    - Also, let's lowercase it all\n",
    "        - HINT: Use **lower()**\n",
    "- Finally, use list comprehension on the lists of positive and negative tweets where **clean_tokens** is applied on each element (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae834172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb450fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe370b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a5141e",
   "metadata": {},
   "source": [
    "### Step 6: Normalize the data\n",
    "- The process of converting a word to its canonical form.\n",
    "- Without normalization, “ran”, “runs”, and “running” would be treated as different words.\n",
    "- Create a lemmatizer of **WordNetLemmatizer()**\n",
    "    - HINT: use **lemmatizer = WordNetLemmatizer()**\n",
    "- Create a helper function to lemmatize\n",
    "    - HINT: Create a helper function **lemmatize(word, tag)**\n",
    "        - Convert tag to **n** or **v** if tag starts with **NN** or **VB**, else **a**\n",
    "        - Return **lemmatizer.lemmatize(word, tag)**\n",
    "- Create a helper function **lemmatize_tokens(tokens: list)**\n",
    "    - Return a list, where each element of **word, tag in pos_tag(...)** of **lemmatize(word, tag)**.\n",
    "- Use list comprehension to normalize the positive and negative tweets\n",
    "    - HINT: apply **lemmatize_tokens(...)** on all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b1e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81104019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cdc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ef7fc28",
   "metadata": {},
   "source": [
    "### Step 7: Prepare data for Model\n",
    "- Example of normalized tweet: **['hopeless', 'tmr', ':(']**\n",
    "    - Should become **({'hopeless': True, 'tmr': True, ':(': True}, 'Negative')**\n",
    "- Hence, the list of tweets (positive and negative) should be converted\n",
    "- HINT: use a dict comprehension inside a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff1e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4a49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728abee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb20c6b",
   "metadata": {},
   "source": [
    "### Step 8: Prepare training and test dataset\n",
    "- Make the dataset of the combined positive and negative datasets\n",
    "- Shuffle the dataset\n",
    "    - Use **shuffle**\n",
    "- Let the training dataset be the first 7000 entries\n",
    "- Let the test dataset be the remaining entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c63307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152756d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a776bf28",
   "metadata": {},
   "source": [
    "### Step 9: Train and test Model\n",
    "- Train the model:\n",
    "    - HINT: **classifier = NaiveBayesClassifier.train(train_data)**\n",
    "- Test the accuracy\n",
    "    - HINT: **classify.accuracy(classifier, test_data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762a442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8b47f6d",
   "metadata": {},
   "source": [
    "### Step 10: Show the most informative features\n",
    "- HINT: Get the 10 most informative features: **classifier.show_most_informative_features(10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5910643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9087a7d5",
   "metadata": {},
   "source": [
    "### Step 11: Test the model\n",
    "- Try your model as follows:\n",
    "    - Define a tweet: **tweet = 'this is fun and awesome'**\n",
    "    - Prepare data for model: **tweet_dict = {token: True for token in lemmatize_tokens(clean_tokens(tweet.split()))}**\n",
    "    - Classify data: **classifier.classify(tweet_dict)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab5c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6840e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b1dd34",
   "metadata": {},
   "source": [
    "### Bonus: The pre-trained Sentiment Intensity Analyzer\n",
    "-  VADER (Valence Aware Dictionary and sEntiment Reasoner) ([Vader](https://www.nltk.org/howto/sentiment.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb5bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cca6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9195b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f3345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
